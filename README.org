* konserve
  :PROPERTIES:
  :CUSTOM_ID: h:6f85a7f4-3694-4703-8c0b-ffcc34f2e5c9
  :END:

[[https://clojurians.slack.com/archives/CB7GJAN0L][https://img.shields.io/badge/slack-join_chat-brightgreen.svg]]
[[https://clojars.org/io.replikativ/konserve][https://img.shields.io/clojars/v/io.replikativ/konserve.svg]]
[[https://circleci.com/gh/replikativ/konserve][https://circleci.com/gh/replikativ/konserve.svg?style=shield]]
[[https://github.com/replikativ/konserve/tree/development][https://img.shields.io/github/last-commit/replikativ/konserve/main.svg]]


[[https://whilo.github.io/old/articles/16/unified-storage-io][Simple durability, made flexible.]]

A simple document store protocol defined with synchronous and [[https://github.com/clojure/core.async][core.async]]
semantics to allow Clojuresque collection operations on associative key-value
stores, both from Clojure and ClojureScript for different backends. Data is
generally serialized with [[https://github.com/edn-format/edn][edn]] semantics or, if supported, as native binary blobs
and can be accessed similarly to =clojure.core= functions =get-in=, =assoc-in=
and =update-in=. =update-in= especially allows to run functions atomically and
returns old and new value. Each operation is run atomically and must be
consistent (in fact ACID), but further consistency is not supported (Riak,
CouchDB and many scalable solutions don't have transactions over keys for that
reason). This is meant to be a building block for more sophisticated storage
solutions (Datomic also builds on kv-stores). A simple append-log for fast
write operations is also implemented.

** Features
   :PROPERTIES:
   :CUSTOM_ID: h:115591f9-90d2-4c25-8499-6f53a8ae4bc6
   :END:

- /cross-platform/ between Clojure and ClojureScript
- /lowest-common denominator interface/ for an associative datastructure
  with =edn= semantics
- /thread-safety with atomicity over key operations/
- /consistent error handling/ for core.async
- /fast serialization/ options (fressian, transit, ...), independent of
  the underlying kv-store
- /very low overhead/ protocol, including direct binary access for high
  throughput
- /no additional dependencies and setup/ required for IndexedDB in the
  browser and the file backend on the JVM and Node.js
- /avoids blocking io/, the filestore for instance will not block any
  thread on reading. Fully asynchronous support for writing and other
  stores is in the pipeline.

*** Garbage Collector
:PROPERTIES:
:CUSTOM_ID: h:5529aa34-11b1-4499-bf62-7fc7be2b8a12
:END:

Konserve has a garbage collector that can be called manually when the store gets
too crowded. For that, the function =konserve.gc/sweep!= allows you to provide a
cut-off date to evict old keys and a whitelist for keys that should be kept.

*** Error handling
:PROPERTIES:
:CUSTOM_ID: h:10edb2cf-b2fc-4cc5-8854-77e6e8a1d82d
:END:

For synchronous execution normal exceptions will be thrown. For asynchronous
error handling we follow the semantics of =go-try= and =<?= introduced [[https://swannodette.github.io/2013/08/31/asynchronous-error-handling][here]]. We
have the [[https://github.com/replikativ/superv.async/][superv.async]] library around the error handling in core.async, but since
there is no need to push it onto the users of konserve, you just need these two
macros that properly handle the errors. =<?= needs to check for an exception and
rethrow and =go-try= needs to catch and pass it along as a return value such
that it does not get lost.

*** Write Hooks
:PROPERTIES:
:CUSTOM_ID: h:c3d7f8a2-9e1b-4d5c-a012-3b4e5f6a7c8d
:END:

Konserve supports write hooks that are invoked after every successful write
operation. This enables reactive patterns like store synchronization, change
logging, or triggering side effects without wrapping the store.

#+BEGIN_SRC clojure
  (require '[konserve.core :as k]
           '[konserve.memory :refer [new-mem-store]])

  (def store (new-mem-store (atom {}) {:sync? true}))

  ;; Register a hook to log all writes
  (k/add-write-hook! store ::my-logger
    (fn [{:keys [api-op key value]}]
      (println "Write:" api-op key "->" value)))

  ;; Writes now trigger the hook
  (k/assoc-in store [:user] {:name "Alice"} {:sync? true})
  ;; Prints: Write: :assoc-in :user -> {:name "Alice"}

  ;; Remove hook when done
  (k/remove-write-hook! store ::my-logger)
#+END_SRC

The hook function receives a map with these keys:
- =:api-op= - The operation (=:assoc-in=, =:update-in=, =:dissoc=, =:bassoc=, =:multi-assoc=, =:multi-dissoc=)
- =:key= - The top-level key being written
- =:key-vec= - Full key path (for =assoc-in= / =update-in=)
- =:value= - The value written
- =:old-value= - Previous value (for update operations)
- =:kvs= - Map of key->value (for =multi-assoc=)
- =:keys= - Collection of keys (for =multi-dissoc=)

Hooks are invoked at the API layer (in =konserve.core=), so they work consistently
across all store backends. Stores must implement the =PWriteHookStore= protocol;
the built-in memory store and default file store both support hooks.

** Usage
   :PROPERTIES:
   :CUSTOM_ID: h:07b8872b-1b84-412b-8133-4dbb9d2a7430
   :END:

Add to your dependencies: [![Clojars Project](https://img.shields.io/clojars/v/io.replikativ/konserve.svg)](https://clojars.org/io.replikativ/konserve)

*Note:* Konserve supports two API styles:
1. *Direct backend imports* - Traditional approach shown below
2. *Unified dispatch* - New polymorphic interface via =konserve.core/connect-store= (see [[#h:unified-store-interface][Unified Store Interface]])

Both approaches are supported and work identically. The unified interface is recommended
for applications that need to switch between backends dynamically or support multiple backends.

*** Synchronous Execution
:PROPERTIES:
:CUSTOM_ID: h:e290028c-78d8-4af6-8742-18b6d46680e3
:END:

Run the following synchronous code if you are not using core.async in your scope:

#+BEGIN_SRC clojure
  (ns test-db
    (:require [konserve.filestore :refer [connect-fs-store]]
              [konserve.core :as k]))

  (def store (connect-fs-store "/tmp/store" :opts {:sync? true}))

  (k/assoc-in store ["foo" :bar] {:foo "baz"} {:sync? true})
  (k/get-in store ["foo"] nil {:sync? true})
  (k/exists? store "foo" {:sync? true})

  (k/assoc-in store [:bar] 42 {:sync? true})
  (k/update-in store [:bar] inc {:sync? true})
  (k/get-in store [:bar] nil {:sync? true})
  (k/dissoc store :bar {:sync? true})

  (k/append store :error-log {:type :horrible} {:sync? true})
  (k/log store :error-log {:sync? true})

  (let [ba (byte-array (* 10 1024 1024) (byte 42))]
    (time (k/bassoc store "banana" ba {:sync? true})))

  (k/bget store "banana"
          (fn [{is :input-stream}]
            (your-read-does-all-work-here is))
          {:sync? true})
#+END_SRC

*** Asynchronous Execution
:PROPERTIES:
:CUSTOM_ID: h:929c501d-2a31-4f05-b231-132f79ee6cb5
:END:

In a ClojureScript REPL you can evaluate the expressions from the REPL
each wrapped in a go-block.

#+BEGIN_SRC clojure
  (ns test-db
    (:require [konserve.memory :refer [new-mem-store]]
              [clojure.core.async :refer [go <!]]))

  (go (def my-db (<! (new-mem-store)))) ;; or (go (def my-db (<!
#+END_SRC

From a Clojure REPL run the following functions for the core.async variants of
the code.
#+BEGIN_SRC clojure
  (ns test-db
    (:require [konserve.filestore :refer [connect-fs-store]]
              [konserve.core :as k]
              [clojure.core.async :refer [go <!]]))

  (go
    (def store (<! (connect-fs-store "/tmp/store")))

    (<! (k/assoc-in store ["foo" :bar] {:foo "baz"}))
    (<! (k/get-in store ["foo"]))
    (<! (k/exists? store "foo"))

    (<! (k/assoc-in store [:bar] 42))
    (<! (k/update-in store [:bar] inc))
    (<! (k/get-in store [:bar]))
    (<! (k/dissoc store :bar))

    (<! (k/append store :error-log {:type :horrible}))
    (<! (k/log store :error-log))

    (let [ba (byte-array (* 10 1024 1024) (byte 42))]
      (time (<! (k/bassoc store "banana" ba)))))
#+END_SRC

** Unified Store Interface
   :PROPERTIES:
   :CUSTOM_ID: h:unified-store-interface
   :END:

Konserve provides a unified multimethod-based interface for connecting to any backend
through =konserve.core/connect-store=. All backends dispatch on a =:backend= key in
the configuration map.

*** Basic Usage

#+BEGIN_SRC clojure
  (require '[konserve.core :as k])

  ;; Memory store
  (def store (k/connect-store {:backend :memory :opts {:sync? true}}))

  ;; File store (JVM and Node.js)
  (def store (k/connect-store {:backend :file
                               :path "/tmp/konserve"
                               :opts {:sync? true}}))

  ;; IndexedDB (browser)
  (go (def store (<! (k/connect-store {:backend :indexeddb
                                       :name "my-db"
                                       :opts {:sync? false}}))))

  ;; External backends (after requiring the backend module)
  (require '[konserve-s3.core])
  (def store (k/connect-store {:backend :s3
                               :bucket "my-bucket"
                               :region "us-east-1"
                               :opts {:sync? true}}))
#+END_SRC

*** Store Lifecycle

#+BEGIN_SRC clojure
  ;; Connect to a store
  (def store (k/connect-store config))

  ;; Create new empty store (equivalent to connect for most backends)
  (def store (k/empty-store config))

  ;; Clean up resources
  (k/release-store config store)

  ;; Delete underlying storage
  (k/delete-store config)
#+END_SRC

*** Available Backends

Built-in:
- =:memory= - In-memory store (all platforms)
- =:file= - File-based store (JVM and Node.js)
- =:indexeddb= - Browser IndexedDB (ClojureScript/browser only)

External (require the corresponding module first):
- =:s3= - AWS S3 ([[https://github.com/replikativ/konserve-s3][konserve-s3]])
- =:dynamodb= - AWS DynamoDB ([[https://github.com/replikativ/konserve-dynamodb][konserve-dynamodb]])
- =:redis= - Redis ([[https://github.com/replikativ/konserve-redis][konserve-redis]])
- =:lmdb= - LMDB ([[https://github.com/replikativ/konserve-lmdb][konserve-lmdb]])
- =:rocksdb= - RocksDB ([[https://github.com/replikativ/konserve-rocksdb][konserve-rocksdb]])

Each backend has specific configuration requirements. See the individual backend
documentation for details.

** Supported Backends
   :PROPERTIES:
   :CUSTOM_ID: h:387ed727-24da-41df-b0f6-cfa03f95bbdd
   :END:

*** In-Memory Store
:PROPERTIES:
:CUSTOM_ID: h:63d979c0-4c4b-41fd-b1e2-e447adee3908
:END:

For simple purposes a memory store wrapping an Atom is implemented for Clojure and ClojureScript.

Usage:

#+BEGIN_SRC clojure
  (ns test-db
    (:require [konserve.memory :refer [new-mem-store]]
              [konserve.core :as k]))

  (def my-db (new-mem-store))
#+END_SRC

*** fs-store
    :PROPERTIES:
    :CUSTOM_ID: h:c88f8eb7-27b1-46ff-bc64-918dd1eb30bc
    :END:

A file-system store in Clojure and for Node are provided as
elementary reference implementations for the two most important platforms. No
setup and no additional dependencies are needed.

The file-system store currently uses [[https://github.com/clojure/data.fressian][fressian]] in Clojure and [[https://github.com/pkpkpk/fress][fress]] in
ClojureScript and is quite efficient. Both implementations use the same on-disk
format and can load the same store (but not concurrently). It also allows to
access values as a normal file-system file, e.g. to open it with a native
database like HDF5 in Java. You can decide not to fsync on every write by a
configuration of ={:sync-blob? false}=, if a potential, but unlikely data loss
is not critical for you (e.g. for a session store). Note that the database will
not be corrupted in this case, you can just lose some write operations before
the crash.

The JVM file store is thoroughly tested using [[https://github.com/google/jimfs][Jimfs]], Google's in-memory NIO
filesystem. This enables testing of file locking, atomic moves, concurrent
access from multiple store instances, and rapid lifecycle operations in a
controlled environment. The file store also supports custom =java.nio.file.FileSystem=
instances via the =:filesystem= parameter for testing or specialized deployments.

Usage (direct import):

#+BEGIN_SRC clojure
  (ns test-db
    (:require [#?(:clj  konserve.filestore
                  :cljs konserve.node-filestore) :refer [connect-fs-store]]
              [konserve.core :as k]))

  (def my-folder "path/to/folder")
  (def my-db (connect-fs-store my-folder))
#+END_SRC

Usage (unified interface):

#+BEGIN_SRC clojure
  (ns test-db
    (:require [konserve.core :as k]))

  (def my-db (k/connect-store {:backend :file
                               :path "path/to/folder"}))
#+END_SRC

*** IndexedDB
    :PROPERTIES:
    :CUSTOM_ID: h:ccbb272e-24b1-4f1e-b525-dd07c4e0e9b4
    :END:

[[https://developer.mozilla.org/en-US/docs/IndexedDB][IndexedDB]] is provided as reference implementation for
ClojureScript browser backends. The IndexedDB store is restricted to the async api only.

Usage:

#+BEGIN_SRC clojure
  (ns test-db
    (:require [clojure.core.async :refer [go <!]]
              [konserve.indexeddb :refer [connect-idb-store]]
              [konserve.core :as k]))

  (go
    (def my-idb-store (<! (connect-idb-store "example-db")))

    ;; Regular operations
    (<! (k/assoc-in my-idb-store [:user] {:name "Alice" :age 30}))
    (<! (k/get-in my-idb-store [:user]))

    ;; Multi-key atomic operations
    (<! (k/multi-assoc my-idb-store {:user1 {:name "Alice"}
                                     :user2 {:name "Bob"}}))

    ;; Efficient bulk retrieval - returns sparse map of found keys
    (<! (k/multi-get my-idb-store [:user1 :user2 :nonexistent]))
    ;; => {:user1 {:name "Alice"} :user2 {:name "Bob"}}

    ;; Atomic bulk delete
    (<! (k/multi-dissoc my-idb-store [:user1 :user2])))
#+END_SRC

The IndexedDB implementation supports atomic multi-key operations (=multi-get=, =multi-assoc=, =multi-dissoc=) through IndexedDB's native transaction model. All operations in a single call either succeed or fail together. =multi-get= returns a sparse map containing only found keys, which is efficient for bulk retrieval during initialization.

*** External Backends
    :PROPERTIES:
    :CUSTOM_ID: h:a8505bd7-5e7a-4e1c-a851-20f11ca9affe
    :END:

External backends integrate seamlessly with konserve through the unified store
interface. After requiring a backend module, it automatically registers with the
multimethod dispatch system and becomes available via =konserve.core/connect-store=.

Usage pattern:

#+BEGIN_SRC clojure
  (require '[konserve.core :as k])
  (require '[konserve-s3.core])  ;; Registers :s3 backend

  ;; Now you can use the backend
  (def s3-store (k/connect-store {:backend :s3
                                  :bucket "my-bucket"
                                  :region "us-east-1"
                                  :store-id "my-app"}))
#+END_SRC

Each backend also exposes its own direct API for advanced use cases. See individual
backend documentation for configuration details.

**** Tiered Store
:PROPERTIES:
:CUSTOM_ID: h:b8f1c3d2-4e5a-4b7c-9123-6d4e8f7a9b2c
:END:

Konserve supports tiered storage with a frontend cache layer and backend persistence layer.
The tiered store combines a fast frontend store (e.g., in-memory) with a durable backend 
store (e.g., filesystem) to optimize for both performance and persistence.

Usage:

#+BEGIN_SRC clojure
  (ns test-db
    (:require [konserve.tiered :refer [connect-tiered-store]]
              [konserve.memory :refer [new-mem-store]]
              [konserve.filestore :refer [connect-fs-store]]
              [clojure.core.async :refer [go <!]]))

  (go
    (def frontend-store (<! (new-mem-store)))
    (def backend-store (<! (connect-fs-store "/tmp/store")))
    (def tiered-store (<! (connect-tiered-store frontend-store backend-store
                                                :write-policy :write-through
                                                :read-policy :frontend-first))))
#+END_SRC

Write policies:
- =:write-through= - Write to backend, then frontend synchronously
- =:write-around= - Write only to backend, invalidate frontend

Read policies:
- =:frontend-first= - Check frontend first, fallback to backend (populates frontend)
- =:frontend-only= - Only read from frontend

The tiered store also supports synchronization between layers and multi-key operations
(=multi-get=, =multi-assoc=, =multi-dissoc=) when both stores support them. During
initialization, =multi-get= combined with =multi-assoc= enables efficient bulk sync
from backend to frontend.

**** Supported backends
:PROPERTIES:
:CUSTOM_ID: h:0100b431-cbaa-4aec-8750-9c02bc0965ba
:END:

- [[https://github.com/replikativ/konserve-jdbc][konserve-jdbc]]
- [[https://github.com/replikativ/konserve-s3][konserve-s3]]
- [[https://github.com/replikativ/konserve-lmdb][konserve-lmdb]]
- [[https://github.com/replikativ/konserve-redis][konserve-redis]]
- [[https://github.com/replikativ/konserve-dynamodb][konserve-dynamodb]]
- [[https://github.com/replikativ/konserve-rocksdb][konserve-rocksdb]]

Please let us know if you are interested in other backends or if you need help
with implementing one.

**** Unofficial backends
:PROPERTIES:
:CUSTOM_ID: h:333570e0-e842-4eca-aef3-9a61fdb67499
:END:

- [[https://github.com/The-Literal-Company/konserve-gcs][konserve-gcs]]

**** Outdated backends
:PROPERTIES:
:CUSTOM_ID: h:2ff08b83-d842-4cdc-a5e4-1d3144e7993a
:END:

The following projects are incompatible with the latest konserve release, but
describe the usage of the underlying store API and could still be helpful to
implement new backends for the underlying store:
- LevelDB:
  [[https://github.com/replikativ/konserve-leveldb][konserve-leveldb]].
- CouchDB:
  [[https://github.com/replikativ/konserve-clutch][konserve-clutch]].
- Riak:
  [[https://github.com/replikativ/konserve-welle][konserve-welle]].
- System component for internal backends:
  [[https://github.com/danielsz/system/blob/master/src/system/components/konserve.clj][system component]]


** Serialization formats
   :PROPERTIES:
   :CUSTOM_ID: h:a4cf3b14-1275-42d4-88f2-89fefb5c6085
   :END:

Different formats for =edn= serialization like [[https://github.com/clojure/data.fressian][fressian]], [[http://blog.cognitect.com/blog/2014/7/22/transit][transit]] or a simple
=pr-str= version are supported and can be combined with different stores. Stores
have a reasonable default setting. You can also extend the serialization
protocol to other formats if you need it. You can provide [[https://github.com/replikativ/incognito][incognito]] support for
records, if you need them.

*** Tagged Literals
    :PROPERTIES:
    :CUSTOM_ID: h:1beb2a17-ca92-42b1-b909-1d043e3d81f6
    :END:

You can read and write custom records according to
[[https://github.com/replikativ/incognito][incognito]].

** Compression and encryption
:PROPERTIES:
:CUSTOM_ID: h:98bf90fd-4778-49da-80d7-58f89f00aec5
:END:

Compression and encryption are supported by the default store implementation
that is used by all current backends. They can be activated in the store
configuration as follows:

#+BEGIN_SRC clojure
{:encryptor {:type :aes
             :key "s3cr3t"}
 :compressor {:type :lz4}}
#+END_SRC

LZ4 compression is currently only supported on the JVM. AES encryption is
supported on both JVM and JS targets with the same cold storage format, i.e. the
same store can be read and written from Clojure and ClojureScript runtimes. We
use AES/CBC/PKCS{5/7}Padding with 256 bit and a different salt for each written
value.

** Backend implementation guide
   :PROPERTIES:
   :CUSTOM_ID: h:7582b1c9-e305-4d51-a808-c10eb447f3de
   :END:

   We provide a [[file:doc/backend.org][backend implementation guide]].

   *New in 2025:* External backends can register with the unified store dispatch
   system by defining multimethod implementations for =konserve.store/connect-store=,
   =konserve.store/empty-store=, =konserve.store/delete-store=, and
   =konserve.store/release-store=. See existing external backends (konserve-s3,
   konserve-lmdb, etc.) for reference implementations.

** Projects building on konserve
   :PROPERTIES:
   :CUSTOM_ID: h:79876ac1-414b-4180-8d65-63737cb3bc53
   :END:

- The protocol is used in production and originates as an elementary
  storage protocol for [[https://github.com/replikativ/replikativ][replikativ]] and [[https://github.com/replikativ/datahike][datahike]].
- [[https://github.com/danielsz/kampbell][kampbell]] maps collections of
  entities to konserve and enforces specs.

** Combined usage with other writers
   :PROPERTIES:
   :CUSTOM_ID: h:8a1b4a06-4b9f-496b-9eb2-52ac953a8e35
   :END:

konserve assumes currently that it accesses its keyspace in the store
exclusively. It uses [[https://github.com/replikativ/hasch][hasch]] to
support arbitrary edn keys and hence does not normally clash with
outside usage even when the same keys are used. To support multiple
konserve clients in the store the backend has to support locking and
proper transactions on keys internally, which is the case for backends
like CouchDB, Redis and Riak.

** License
   :PROPERTIES:
   :CUSTOM_ID: h:8153b6f6-d253-4863-86b4-038dd383b6fe
   :END:

Copyright © 2014-2025 Christian Weilbach and contributors

Distributed under the Eclipse Public License either version 1.0 or (at
your option) any later version.
